{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv9TKT9xSiFlo+sCor2lx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acb-code/data-science-learning/blob/main/mnist_classifier_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QeDoK1Lsa_Ns"
      },
      "outputs": [],
      "source": [
        "# https://github.com/NVDLI/LDL/blob/main/pt_framework/c5e1_mnist_learning.ipynb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "torch.manual_seed(7)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load training dataset into single batch to compute mean and std\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = MNIST(root='./pt_data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
        "data = next(iter(trainloader))\n",
        "mean = data[0].mean()\n",
        "std = data[0].std()\n",
        "print(mean, std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLLT7ztkbFxW",
        "outputId": "7a35a89f-1202-4733-9005-56ccc6e82bf8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 23.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 558kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.43MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.69MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1307) tensor(0.3081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the normalized training and test sets\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean, std)])\n",
        "\n",
        "trainset = MNIST(root='./pt_data', train=True, download=True, transform=transform)\n",
        "testset = MNIST(root='./pt_data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "K6428C_obF6g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28, 25),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(25, 10),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# initialize weights\n",
        "for module in model.modules():\n",
        "  if isinstance(module, nn.Linear):\n",
        "    nn.init.uniform_(module.weight, a=-0.1, b=0.1)\n",
        "    nn.init.constant_(module.bias, 0.0)"
      ],
      "metadata": {
        "id": "3l-4XEoTcmpH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  model.train()\n",
        "  train_loss = 0.0\n",
        "  train_correct = 0\n",
        "  train_batches = 0\n",
        "  for inputs, targets in trainloader:\n",
        "    # move data to GPU\n",
        "    one_hot_targets = nn.functional.one_hot(targets, num_classes=10).float()\n",
        "    inputs, targets, one_hot_targets = inputs.to(device), targets.to(device), one_hot_targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, one_hot_targets)\n",
        "\n",
        "    _, indices = torch.max(outputs, 1)\n",
        "    train_correct += (indices == targets).sum().item()\n",
        "    train_batches += 1\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss = train_loss / train_batches\n",
        "  train_acc = train_correct / (train_batches * BATCH_SIZE)\n",
        "\n",
        "  # eval model\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  test_correct = 0\n",
        "  test_batches = 0\n",
        "  for inputs, targets in testloader:\n",
        "    one_hot_targets = nn.functional.one_hot(targets, num_classes=10).float()\n",
        "    inputs, targets, one_hot_targets = inputs.to(device), targets.to(device), one_hot_targets.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_function(outputs, one_hot_targets)\n",
        "    _, indices = torch.max(outputs, 1)\n",
        "    test_correct += (indices == targets).sum().item()\n",
        "    test_batches += 1\n",
        "    test_loss += loss.item()\n",
        "\n",
        "  test_loss = test_loss / test_batches\n",
        "  test_acc = test_correct / (test_batches * BATCH_SIZE)\n",
        "\n",
        "  print(f'Epoch {i+1}/{EPOCHS} loss: {train_loss:.4f} - acc: {train_acc:0.4f} - val_loss: {test_loss:.4f} - val_acc: {test_acc:0.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZSw8I3NcmrW",
        "outputId": "e717bbe3-f394-4b5e-d22e-09b1bd90a757"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 loss: 0.0501 - acc: 0.7087 - val_loss: 0.0238 - val_acc: 0.8955\n",
            "Epoch 2/20 loss: 0.0198 - acc: 0.9038 - val_loss: 0.0163 - val_acc: 0.9153\n",
            "Epoch 3/20 loss: 0.0156 - acc: 0.9167 - val_loss: 0.0140 - val_acc: 0.9245\n",
            "Epoch 4/20 loss: 0.0140 - acc: 0.9225 - val_loss: 0.0129 - val_acc: 0.9276\n",
            "Epoch 5/20 loss: 0.0129 - acc: 0.9281 - val_loss: 0.0126 - val_acc: 0.9282\n",
            "Epoch 6/20 loss: 0.0122 - acc: 0.9312 - val_loss: 0.0118 - val_acc: 0.9325\n",
            "Epoch 7/20 loss: 0.0116 - acc: 0.9347 - val_loss: 0.0115 - val_acc: 0.9331\n",
            "Epoch 8/20 loss: 0.0112 - acc: 0.9368 - val_loss: 0.0111 - val_acc: 0.9360\n",
            "Epoch 9/20 loss: 0.0108 - acc: 0.9393 - val_loss: 0.0109 - val_acc: 0.9352\n",
            "Epoch 10/20 loss: 0.0104 - acc: 0.9416 - val_loss: 0.0106 - val_acc: 0.9372\n",
            "Epoch 11/20 loss: 0.0102 - acc: 0.9423 - val_loss: 0.0104 - val_acc: 0.9398\n",
            "Epoch 12/20 loss: 0.0098 - acc: 0.9451 - val_loss: 0.0102 - val_acc: 0.9393\n",
            "Epoch 13/20 loss: 0.0096 - acc: 0.9458 - val_loss: 0.0101 - val_acc: 0.9415\n",
            "Epoch 14/20 loss: 0.0094 - acc: 0.9478 - val_loss: 0.0100 - val_acc: 0.9404\n",
            "Epoch 15/20 loss: 0.0092 - acc: 0.9488 - val_loss: 0.0098 - val_acc: 0.9420\n",
            "Epoch 16/20 loss: 0.0090 - acc: 0.9493 - val_loss: 0.0098 - val_acc: 0.9411\n",
            "Epoch 17/20 loss: 0.0088 - acc: 0.9506 - val_loss: 0.0095 - val_acc: 0.9424\n",
            "Epoch 18/20 loss: 0.0087 - acc: 0.9514 - val_loss: 0.0095 - val_acc: 0.9426\n",
            "Epoch 19/20 loss: 0.0086 - acc: 0.9522 - val_loss: 0.0094 - val_acc: 0.9431\n",
            "Epoch 20/20 loss: 0.0084 - acc: 0.9531 - val_loss: 0.0093 - val_acc: 0.9433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "ax = ax.ravel()\n",
        "\n",
        "ax[0].plot(range(EPOCHS), train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "aEU8Nv2npggi",
        "outputId": "7d0d66e6-d177-4b81-9fda-3ee47142789e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (20,) and (1,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6e4390c0b083>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \"\"\"\n\u001b[1;32m   1776\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mambiguous_fmt_datakey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    495\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONmrcDLRcmts",
        "outputId": "8adab676-3667-40aa-9c15-571d34ce20d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.008391492390549699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46a4lwnUbF9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}